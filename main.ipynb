{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4277ffd8-7010-4875-bc88-029987c9440a",
   "metadata": {},
   "source": [
    "# Generative AI using Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c0d2f3-2307-49bf-9b9a-ccd047efdcf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Open Source model running locally via Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7dc54-4079-48c3-94c4-d89a2a9d1cfd",
   "metadata": {},
   "source": [
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faeb1bf-afbc-479e-9c9a-83a38b3337e4",
   "metadata": {},
   "source": [
    "## Installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new terminal and enter `ollama serve`  \n",
    "And in another terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7db3d4-2930-4f71-9e4b-cccf1428fdcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "162b8f25-95ad-4fa5-8ff1-d06762903cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ebb3b96-de98-4c9e-a8e9-bb1879854cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b993141c-7d33-4a57-9a58-673f727f81cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa47078a-da17-4283-b4a8-31181fd2c838",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as articles, social media posts, and product descriptions, saving time and resources for businesses.\n",
      "2. **Marketing Automation**: Generative AI can help automate marketing processes by generating personalized messages, email campaigns, and ad copy that resonate with target audiences.\n",
      "3. **Customer Service**: Chatbots powered by generative AI can provide 24/7 customer support, responding to queries and resolving issues in a timely and efficient manner.\n",
      "4. **Data Analysis**: Generative AI can be used to analyze large datasets, identify patterns, and predict trends, helping businesses make data-driven decisions.\n",
      "5. **Product Design**: Generative AI can assist in designing new products by generating 3D models, prototypes, and even entire product lines.\n",
      "6. **Creative Writing**: Generative AI can help writers with tasks such as suggesting alternative phrases, completing sentences, or even generating entire stories.\n",
      "7. **Music and Audio Generation**: Generative AI can be used to create music, audio effects, and soundscapes for various applications, including film, gaming, and advertising.\n",
      "8. **Image and Video Generation**: Generative AI can generate high-quality images and videos that mimic real-world scenes, making it useful for applications such as product photography and video production.\n",
      "9. **Language Translation**: Generative AI-powered translation tools can help businesses communicate with customers in different languages, improving customer satisfaction and global reach.\n",
      "10. **Predictive Maintenance**: Generative AI can be used to predict equipment failures, reducing downtime and increasing overall efficiency in industries such as manufacturing and energy.\n",
      "\n",
      "Some specific examples of business applications of generative AI include:\n",
      "\n",
      "* **Salesforce**: Uses generative AI to personalize customer interactions and generate sales content.\n",
      "* **Microsoft**: Employs generative AI for content creation, marketing automation, and language translation.\n",
      "* **DHL**: Utilizes generative AI to optimize logistics and predict delivery times.\n",
      "* **BMW**: Leverages generative AI for product design and virtual prototyping.\n",
      "\n",
      "These are just a few examples of the many innovative applications of generative AI in business.\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b2cfda-6ce8-49c3-b333-64132b8b8bc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3159ff0a-cf1b-4b09-944c-45050ea37ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ollama'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mollama\u001b[39;00m\n\u001b[1;32m      3\u001b[0m response \u001b[38;5;241m=\u001b[39m ollama\u001b[38;5;241m.\u001b[39mchat(model\u001b[38;5;241m=\u001b[39mMODEL, messages\u001b[38;5;241m=\u001b[39mmessages)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ollama'"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f1000a-1a20-46fb-95bf-8744154d31fe",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f9ad0-81a9-4f27-97c0-5e03d76b9190",
   "metadata": {},
   "source": [
    "Both the API approach and the local Ollama setup provide the same functionality in terms of interacting with Ollama models. However, using the Ollama Python package, rather than making direct HTTP calls, offers a more elegant and streamlined solution. The Python package simplifies the process by abstracting away the complexity of handling raw HTTP requests, making the code cleaner, more readable, and easier to maintain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f2a407-ca69-4f4d-8c62-cf2af2bbb882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
